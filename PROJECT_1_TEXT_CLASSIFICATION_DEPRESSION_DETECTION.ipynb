{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PROJECT_1_TEXT_CLASSIFICATION_DEPRESSION_DETECTION.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1AfMChGKAGypx0jZHb1w8Rk4TKW18_IqJ",
      "authorship_tag": "ABX9TyNDmhMIXS6UORwiWl4Xp34E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awannabecs/MY-FUNCTION-NAME/blob/main/PROJECT_1_TEXT_CLASSIFICATION_DEPRESSION_DETECTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "f22i0WcfXOdv",
        "outputId": "551735d5-de5a-4d8b-dea4-6aeba2464eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'play'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "#import the libraries \n",
        "import numpy as  np\n",
        "import pandas as pd \n",
        "import tensorflow as tf\n",
        "import nltk \n",
        "import re\n",
        "import matplotlib.pyplot as plt \n",
        "nltk.download(\"punkt\")\n",
        "tokenizer = nltk.word_tokenize\n",
        "tokenizer(\"go out\")\n",
        "stemmer = nltk.PorterStemmer().stem\n",
        "stemmer(\"played\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/MAIN_DATA\")\n",
        "df.dropna(inplace=False)"
      ],
      "metadata": {
        "id": "fxtuuIv5X611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c00f9abf-b9a3-42e8-f52b-9006078b7173"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  Unnamed: 0.1  depressed  \\\n",
              "0              0           0.0        0.0   \n",
              "1              1           1.0        0.0   \n",
              "2              2           2.0        1.0   \n",
              "3              3           3.0        1.0   \n",
              "4              4           4.0        0.0   \n",
              "...          ...           ...        ...   \n",
              "1790         178        1210.0        1.0   \n",
              "1791         179        1212.0        1.0   \n",
              "1792         180        1233.0        1.0   \n",
              "1793         181        1234.0        1.0   \n",
              "1794         182        1250.0        1.0   \n",
              "\n",
              "                                                   text  \n",
              "0                 I know where you're coming from mate.  \n",
              "1                           I felt like this last year.  \n",
              "2     I remember around this time last year, i was h...  \n",
              "3     i was heavily addicted to meth, it was literal...  \n",
              "4     I worked like 70+hours in a warehouse job, 2 h...  \n",
              "...                                                 ...  \n",
              "1790                                  hate shattered me  \n",
              "1791   but I know depression and drug addiction don'...  \n",
              "1792   I feel a lot of deeply depressed souls have d...  \n",
              "1793            anxiety and mental breakdowns...|0|0|0|  \n",
              "1794                         learn to deal w my anxiety  \n",
              "\n",
              "[1790 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-722e96df-5e2d-4216-b645-2ae99fb63602\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>depressed</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I know where you're coming from mate.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I felt like this last year.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I remember around this time last year, i was h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>i was heavily addicted to meth, it was literal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I worked like 70+hours in a warehouse job, 2 h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1790</th>\n",
              "      <td>178</td>\n",
              "      <td>1210.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>hate shattered me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1791</th>\n",
              "      <td>179</td>\n",
              "      <td>1212.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>but I know depression and drug addiction don'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1792</th>\n",
              "      <td>180</td>\n",
              "      <td>1233.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I feel a lot of deeply depressed souls have d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1793</th>\n",
              "      <td>181</td>\n",
              "      <td>1234.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>anxiety and mental breakdowns...|0|0|0|</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1794</th>\n",
              "      <td>182</td>\n",
              "      <td>1250.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>learn to deal w my anxiety</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1790 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-722e96df-5e2d-4216-b645-2ae99fb63602')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-722e96df-5e2d-4216-b645-2ae99fb63602 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-722e96df-5e2d-4216-b645-2ae99fb63602');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create the word2number dictionary\n",
        "tokens = []\n",
        "for i in range(len(df)):\n",
        "  words = []\n",
        "  try:\n",
        "    words.extend(tokenizer(df.iloc[i][\"text\"].lower()))\n",
        "    for word in words:\n",
        "      word = word\n",
        "      tokens.append(stemmer(word))\n",
        "  except Exception as e:\n",
        "    print(df.iloc[i][\"text\"])\n",
        "\n",
        "tokens = set(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbrKAVxQbBKk",
        "outputId": "dcde9833-62f6-4ec4-9b1b-b44ca6b71f94"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "somelist = [\" '//twitter.com/ltsharrypotter/status/984475138933579782',\", '//t.co/yacazn2t0h',\n",
        "            \"dk_mok\", '70+hour', 'much|1|0|4|', 'collection|1|0|3|',\"20\",]\n",
        "pattern = \"\"\"\\/?\\/?twitter.com/.+|\n",
        "\\/?\\/?t.co\\/?.+|  \n",
        "_|\n",
        "\\d+|\n",
        "\\|d\\|\\d\\|\\d|\n",
        "\"\"\"\n",
        "for word in somelist:\n",
        "  word = re.sub(pattern,\"\",word)\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrbpeNfqbZZn",
        "outputId": "4fadc84c-ab2a-4f1b-82e0-7d4a55e92389"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " '\n",
            "//t.co/yacazn2t0h\n",
            "dk_mok\n",
            "70+hour\n",
            "much|1|0|4|\n",
            "collection|1|0|3|\n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token2index_dict = {\"OOV\":0}\n",
        "index2token_dict = {0:\"OOV\"}\n",
        "for index,token in enumerate(tokens):\n",
        "  token2index_dict[token] = index+1\n",
        "  index2token_dict[index+1] = token"
      ],
      "metadata": {
        "id": "3YagIXVaqgCo"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def token2index_function(dict,sent):\n",
        "  result_sent = []\n",
        "  for token in sent.split(\" \"):\n",
        "    result_sent.append(dict.get(token,0))\n",
        "  return result_sent\n",
        "\n",
        "\n",
        "def index2token_function(dict,index):\n",
        "  return dict.get(index,\"OOV\")"
      ],
      "metadata": {
        "id": "tf4ViBifw9lI"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make the sentences same-lengthed \n",
        "#find the max length\n",
        "max_length = 0\n",
        "for sent in range(len(df)):\n",
        "  try:\n",
        "    words = nltk.word_tokenize(df.iloc[sent][\"text\"])\n",
        "  except Exception as e:\n",
        "    print(df.iloc[sent][\"text\"])\n",
        "  if len(words) > max_length:\n",
        "    max_length = len(words)"
      ],
      "metadata": {
        "id": "9GRKoCLy0W6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe4b101f-0b0b-4ac6-c8a0-c6348950c957"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = [1,2,3,4,5,6,7,8]\n",
        "def same_lengther(vector,max_length):\n",
        "  zeros = np.zeros(max_length - len(vector))\n",
        "  vector.extend(zeros)\n",
        "  return vector"
      ],
      "metadata": {
        "id": "mTN-IxkN3KFc"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define X and y\n",
        "X = []\n",
        "y = []\n",
        "X_vector = []\n",
        "\n",
        "\n",
        "for i in range(len(df)):\n",
        "  feature = df[\"text\"].iloc[i]\n",
        "  label = int(df[\"depressed\"].iloc[i])\n",
        "\n",
        "  try:\n",
        "    feature_vector = token2index_function(token2index_dict,feature)\n",
        "    X_vector.append(same_lengther(feature_vector,max_length))\n",
        "    y.append(label)\n",
        "    X.append(feature.lower())\n",
        "  except Exception as e:\n",
        "    print(i)\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRjE5Oy_8iGO",
        "outputId": "5d6a7108-2377-4dc2-ec9b-315aa0bd85e3"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "534\n",
            "727\n",
            "979\n",
            "1019\n",
            "1242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_vector = np.array(X_vector).astype(\"float32\")\n",
        "y = np.array(y).astype(\"float32\")\n",
        "\n",
        "X_vector.shape,y.shape\n",
        "y = pd.get_dummies(y)"
      ],
      "metadata": {
        "id": "Dxkx0WNI98gz"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(666)\n",
        "model1 = tf.keras.Sequential()\n",
        "model1.add(tf.keras.layers.Dense(128,activation=\"relu\"))\n",
        "model1.add(tf.keras.layers.Dense(64,activation=\"relu\"))\n",
        "model1.add(tf.keras.layers.Dense(32,activation=\"relu\"))\n",
        "model1.add(tf.keras.layers.Dense(16,activation=\"relu\"))\n",
        "model1.add(tf.keras.layers.Dense(8,activation=\"relu\"))\n",
        "model1.add(tf.keras.layers.Dense(4,activation=\"relu\"))\n",
        "model1.add(tf.keras.layers.Dense(2,activation=\"sigmoid\"))\n",
        "\n",
        "model1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "               optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics=[\"accuracy\"])\n",
        "\n",
        "model1.fit(X_vector,y,epochs=100)"
      ],
      "metadata": {
        "id": "7bq22Qhmy3Fm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d11b05dd-5ceb-49a2-ac63-a66b5d426100"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "81/81 [==============================] - 1s 3ms/step - loss: 6.9467 - accuracy: 0.5205\n",
            "Epoch 2/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.7126 - accuracy: 0.4986\n",
            "Epoch 3/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5010\n",
            "Epoch 4/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.5018\n",
            "Epoch 5/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5018\n",
            "Epoch 6/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5018\n",
            "Epoch 7/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5018\n",
            "Epoch 8/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5018\n",
            "Epoch 9/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5018\n",
            "Epoch 10/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5018\n",
            "Epoch 11/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5014\n",
            "Epoch 12/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5018\n",
            "Epoch 13/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5018\n",
            "Epoch 14/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5014\n",
            "Epoch 15/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.4994\n",
            "Epoch 16/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4873\n",
            "Epoch 17/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 18/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 19/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 20/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 21/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4819\n",
            "Epoch 22/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 23/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 24/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 25/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 26/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 27/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 28/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 29/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 30/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 31/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 32/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4842\n",
            "Epoch 33/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4920\n",
            "Epoch 34/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 35/100\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.4881\n",
            "Epoch 36/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4998\n",
            "Epoch 37/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 38/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 39/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 40/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 41/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 42/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4881\n",
            "Epoch 43/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 44/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 45/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 46/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 47/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 48/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4936\n",
            "Epoch 49/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 50/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 51/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4904\n",
            "Epoch 52/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 53/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 54/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 55/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4881\n",
            "Epoch 56/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4807\n",
            "Epoch 57/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 58/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 59/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 60/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 61/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 62/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 63/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 64/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 65/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4815\n",
            "Epoch 66/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 67/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 68/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4904\n",
            "Epoch 69/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 70/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 71/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4756\n",
            "Epoch 72/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4819\n",
            "Epoch 73/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4998\n",
            "Epoch 74/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 75/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 76/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 77/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4932\n",
            "Epoch 78/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 79/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 80/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 81/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4830\n",
            "Epoch 82/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 83/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 84/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 85/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 86/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 87/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 88/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 89/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 90/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 91/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.4842\n",
            "Epoch 92/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 93/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4842\n",
            "Epoch 94/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 95/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 96/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4924\n",
            "Epoch 97/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.4854\n",
            "Epoch 98/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n",
            "Epoch 99/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.4823\n",
            "Epoch 100/100\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5014\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f627466ded0>"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.iloc[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BKhvfoVKFsc",
        "outputId": "0c5de0ed-0e9e-4ca3-ef0c-26a50418d2a3"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    1\n",
              "1.0    0\n",
              "Name: 1, dtype: uint8"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# ***since we are getting aweful results, we geuess that our vectors are too sparse, so first we try to plot a histogram to see how many instances of different sizes we have.***\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zlDXaNU0-iIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get a list of the length of the sentences \n",
        "len_sentences_list = []\n",
        "for i in range(len(df)):\n",
        "  try:\n",
        "    words = nltk.word_tokenize(df[\"text\"].iloc[i])\n",
        "    len_sentences_list.append(len(words))\n",
        "  except Exception as e:\n",
        "    print(df[\"text\"].iloc[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wFUUO1r-hRP",
        "outputId": "45e2f0f7-c0af-4756-fdb7-f8d833526bf3"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the list as a histogram\n",
        "plt.hist(len_sentences_list)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KJwlgddabDpx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "aae98b39-1e23-445d-f3d7-011d8f81531d"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# ***as you can see, we only have under 100 sentences with the length of 40,let alone the 121...so it's better to change the padding by setting the maximum length to be around 40 so we would not have such sparse vectors***\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NmBkz1zZAWJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1_X = []\n",
        "model1_y = []\n",
        "len_sentences_list = []\n",
        "for i in range(len(X)):\n",
        "  words = nltk.word_tokenize(X[i])\n",
        "  if len(words) <= 40:\n",
        "    model1_X.append(X[i])\n",
        "    len_sentences_list.append(len(words))\n",
        "    model1_y.append(i)"
      ],
      "metadata": {
        "id": "X44ccJiRAQGD"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's replot the histogram to see what happened\n",
        "plt.hist(len_sentences_list)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "r8CNTkt4CFLa",
        "outputId": "5443ab29-de21-41e5-d9be-b7bea8107224"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# ***That looks better***\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FkniBA6LCyqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1_X_vectors = []\n",
        "for sentence in model1_X:\n",
        "  index_tokens = token2index_function(token2index_dict,sentence)\n",
        "  model1_X_vectors.append(np.array(same_lengther(index_tokens,40)))  \n",
        "\n",
        "model1_y = np.array(model1_y).astype(\"float32\")\n",
        "model1_y = pd.get_dummies(model1_y)"
      ],
      "metadata": {
        "id": "iE7we3PJCj2L"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1_y.iloc[9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sWIR9RZD3rn",
        "outputId": "07dc1346-5970-4053-97df-205e12df695f"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0       0\n",
              "1.0       0\n",
              "2.0       0\n",
              "3.0       0\n",
              "4.0       0\n",
              "         ..\n",
              "2560.0    0\n",
              "2561.0    0\n",
              "2562.0    0\n",
              "2563.0    0\n",
              "2564.0    0\n",
              "Name: 9, Length: 2526, dtype: uint8"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(666)\n",
        "model1 = tf.keras.Sequential()\n",
        "model1.add(tf.keras.layers.Dense(128,activation=\"relu\"))\n",
        "model1.add(tf.keras.layers.Dense(64,activation=\"relu\"))\n",
        "model1.add(tf.keras.layers.Dense(32,activation=\"relu\"))\n",
        "model1.add(tf.keras.layers.Dense(16,activation=\"relu\"))\n",
        "model1.add(tf.keras.layers.Dense(8,activation=\"relu\"))\n",
        "model1.add(tf.keras.layers.Dense(4,activation=\"relu\"))\n",
        "model1.add(tf.keras.layers.Dense(2,activation=\"sigmoid\"))\n",
        "\n",
        "model1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "               optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics=[\"accuracy\"])\n",
        "\n",
        "model1.fit(model1_X_vectors,model1_y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "1xaV6AIeEuWn",
        "outputId": "6f8abb30-4b07-47c6-e32d-5470c9eff854"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-174-baf14f7db62a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                metrics=[\"accuracy\"])\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1_X_vectors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel1_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                            for i in tf.nest.flatten(single_data)))\n\u001b[1;32m   1652\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40...\n  y sizes: 2526\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8oeMoCJBHdbv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}